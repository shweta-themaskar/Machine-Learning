{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#reading the dataset\n",
    "df=pd.read_csv('train_clean_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>married_Yes</th>\n",
       "      <th>education_Not Graduate</th>\n",
       "      <th>property_area_Semiurban</th>\n",
       "      <th>property_area_Urban</th>\n",
       "      <th>self_employed_Yes</th>\n",
       "      <th>Loan_status_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LP001005</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LP001006</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LP001008</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LP001011</td>\n",
       "      <td>2</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Loan_ID Dependents  ApplicantIncome  CoapplicantIncome  \\\n",
       "0           1  LP001003          1             4583             1508.0   \n",
       "1           2  LP001005          0             3000                0.0   \n",
       "2           3  LP001006          0             2583             2358.0   \n",
       "3           4  LP001008          0             6000                0.0   \n",
       "4           5  LP001011          2             5417             4196.0   \n",
       "\n",
       "   LoanAmount  Loan_Amount_Term  Credit_History  gender_Male  married_Yes  \\\n",
       "0       128.0             360.0             1.0            1            1   \n",
       "1        66.0             360.0             1.0            1            1   \n",
       "2       120.0             360.0             1.0            1            1   \n",
       "3       141.0             360.0             1.0            1            0   \n",
       "4       267.0             360.0             1.0            1            1   \n",
       "\n",
       "   education_Not Graduate  property_area_Semiurban  property_area_Urban  \\\n",
       "0                       0                        0                    0   \n",
       "1                       0                        0                    1   \n",
       "2                       1                        0                    1   \n",
       "3                       0                        0                    1   \n",
       "4                       0                        0                    1   \n",
       "\n",
       "   self_employed_Yes  Loan_status_Y  \n",
       "0                  0              0  \n",
       "1                  1              1  \n",
       "2                  0              1  \n",
       "3                  0              1  \n",
       "4                  1              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 15 columns):\n",
      "Unnamed: 0                 517 non-null int64\n",
      "Loan_ID                    517 non-null object\n",
      "Dependents                 517 non-null object\n",
      "ApplicantIncome            517 non-null int64\n",
      "CoapplicantIncome          517 non-null float64\n",
      "LoanAmount                 517 non-null float64\n",
      "Loan_Amount_Term           517 non-null float64\n",
      "Credit_History             517 non-null float64\n",
      "gender_Male                517 non-null int64\n",
      "married_Yes                517 non-null int64\n",
      "education_Not Graduate     517 non-null int64\n",
      "property_area_Semiurban    517 non-null int64\n",
      "property_area_Urban        517 non-null int64\n",
      "self_employed_Yes          517 non-null int64\n",
      "Loan_status_Y              517 non-null int64\n",
      "dtypes: float64(4), int64(9), object(2)\n",
      "memory usage: 60.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].unique()\n",
    "df['Married'].unique()\n",
    "df['Education'].unique()\n",
    "df['Property_Area'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Male = pd.get_dummies(df['Gender'],drop_first=True,prefix='gender')\n",
    "married = pd.get_dummies(df['Married'],drop_first=True,prefix='married')\n",
    "education  = pd.get_dummies(df['Education'],drop_first=True,prefix='education')\n",
    "Property_area = pd.get_dummies(df['Property_Area'],drop_first=True,prefix='property_area')\n",
    "Self_Employed = pd.get_dummies(df['Self_Employed'],drop_first=True,prefix='self_employed')\n",
    "Loan_status = pd.get_dummies(df['Loan_Status'],drop_first=True,prefix='Loan_status')\n",
    "\n",
    "df = pd.concat([df,Male,married,education,Property_area,Self_Employed,\n",
    "                Loan_status],axis = 1)\n",
    "df.drop(['Gender','Married','Education','Property_Area','Self_Employed',\n",
    "         'Loan_Status'],axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename({'Yes': 'Self_Employed'}, axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = df.drop(['Loan_status_Y','Loan_ID','Dependents'],axis=1)\n",
    "y = df['Loan_status_Y']\n",
    "\n",
    "#split dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y, test_size=0.3,\n",
    "                                                       random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "model = BaggingClassifier(LogisticRegression(),n_estimators=100,\n",
    "                          max_samples=1.0, max_features=1.0,n_jobs = 2 \n",
    "                          )\n",
    "\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10,criterion='entropy',max_depth=3)\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import tree\n",
    "model = BaggingRegressor(tree.DecisionTreeRegressor(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters used in the  algorithms:\n",
    "\n",
    "**base_estimator**:\n",
    "It defines the base estimator to fit on random subsets of the dataset.\n",
    "When nothing is specified, the base estimator is a decision tree.\n",
    "\n",
    "**n_estimators**:\n",
    "It is the number of base estimators to be created.\n",
    "The number of estimators should be carefully tuned as a large number would take a very long time to run, while a very small number might not provide the best results.\n",
    "\n",
    "**max_samples**:\n",
    "This parameter controls the size of the subsets.\n",
    "It is the maximum number of samples to train each base estimator.\n",
    "\n",
    "**max_features**:\n",
    "Controls the number of features to draw from the whole dataset.\n",
    "It defines the maximum number of features required to train each base estimator.\n",
    "\n",
    "**n_jobs**:\n",
    "The number of jobs to run in parallel.\n",
    "Set this value equal to the cores in your system.\n",
    "If -1, the number of jobs is set to the number of cores.\n",
    "\n",
    "**random_state**:\n",
    "It specifies the method of random split. When random state value is same for two models, the random selection is same for both models.\n",
    "This parameter is useful when you want to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(random_state=1, learning_rate=1)#, algorithm='SAMME.E') # \n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(learning_rate=0.01,,random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model= GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xg Boost Classification problem\n",
    "\n",
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG boost Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.empty((0,1),float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.empty((0,1),float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def Stacking(model,train,y,test,n_fold):\n",
    "    '''\n",
    "    n_fold=10,\n",
    "    train=x_train,\n",
    "    test=x_test,\n",
    "    y=y_train\n",
    "    \n",
    "    StratifiedKFold: used for k folds cross varidation.\n",
    "    Stacking function is returning 2D numpy arrays \n",
    "    \n",
    "    '''\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    \n",
    "    \n",
    "    test_pred=np.empty((0,1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    \n",
    "    \n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        \n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "        \n",
    "    test_pred=np.append(test_pred,model.predict(test))\n",
    "    \n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll create two base models – decision tree and knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model1 = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)\n",
    "\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
    "\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a third model, logistic regression, on the predictions of the decision tree and knn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df,y_train)\n",
    "model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify the above explanation, the stacking model we have created has only two levels. The decision tree and knn models are built at level zero, while a logistic regression model is built at level one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
